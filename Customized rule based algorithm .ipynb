{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:/Users/Dell/Pictures/senti/initialdata.csv\")\n",
    "initial=pd.read_csv(r\"C:/Users/Dell/Pictures/senti/initialdata.csv\")\n",
    "\n",
    "#data['Review'] = data['title'].str.cat(data['content'], sep =\". \") \n",
    "#initial=data[['Review']]\n",
    "#initial.head()\n",
    "#initial.to_csv(\"C:/Users/Dell/Pictures/senti/initialdata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Noting Special. Ok Product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Review. Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Indian brand keeping to its name, best for me!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Satisfied. Bought it for INR 152 during the Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Damaged. Unexpectedlly... One bottle is damaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                             Review\n",
       "0          0                        Noting Special. Ok Product.\n",
       "1          1                                       Review. Good\n",
       "2          2  Indian brand keeping to its name, best for me!...\n",
       "3          3  Satisfied. Bought it for INR 152 during the Am...\n",
       "4          4    Damaged. Unexpectedlly... One bottle is damaged"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using spaCy for dependency parsing which forms the crux of aspect extraction\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load('C:/Users/Dell/Anaconda3/Lib/site-packages/en_core_web_lg/en_core_web_lg-2.1.0', parse=True, tag=True, entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPOUND WORDS\n",
    "competitors = ['marico','P&G','hindustan unilever limited','dabur','petra foods','nestle'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_terms = []\n",
    "comp_terms = []\n",
    "easpect_terms = []\n",
    "ecomp_terms = []\n",
    "enemy = []\n",
    "\n",
    "def get_aspect_adj(data):\n",
    "    for x in tqdm(range(len(data['Review']))):\n",
    "        amod_pairs = []\n",
    "        advmod_pairs = []\n",
    "        compound_pairs = []\n",
    "        xcomp_pairs = []\n",
    "        neg_pairs = []\n",
    "        eamod_pairs = []\n",
    "        eadvmod_pairs = []\n",
    "        ecompound_pairs = []\n",
    "        eneg_pairs = []\n",
    "        excomp_pairs = []\n",
    "        enemlist = []\n",
    "        if len(str(data['Review'][x])) != 0:\n",
    "            lines = str(data['Review'][x]).replace('*',' ').replace('-',' ').replace('so ',' ').replace('be ',' ').replace('are ',' ').replace('just ',' ').replace('get ','').replace('were ',' ').replace('When ','').replace('when ','').replace('again ',' ').replace('where ','').replace('how ',' ').replace('has ',' ').replace('Here ',' ').replace('here ',' ').replace('now ',' ').replace('see ',' ').replace('why ',' ').split('.')       \n",
    "            for line in lines:\n",
    "                enem_list = []\n",
    "                for eny in competitors:\n",
    "                    enem = re.search(eny,line)\n",
    "                    if enem is not None:\n",
    "                        enem_list.append(enem.group())\n",
    "                if len(enem_list)==0:\n",
    "                    doc = nlp(line)\n",
    "                    str1=''\n",
    "                    str2=''\n",
    "                    for token in doc:\n",
    "                        if token.pos_ is 'NOUN':\n",
    "                            for j in token.lefts:\n",
    "                                if j.dep_ == 'compound':\n",
    "                                    compound_pairs.append((j.text+' '+token.text,token.text))\n",
    "                                if j.dep_ is 'amod' and j.pos_ is 'ADJ': #primary condition\n",
    "                                    str1 = j.text+' '+token.text\n",
    "                                    amod_pairs.append(j.text+' '+token.text)\n",
    "                                    for k in j.lefts:\n",
    "                                        if k.dep_ is 'advmod': #secondary condition to get adjective of adjectives\n",
    "                                            str2 = k.text+' '+j.text+' '+token.text\n",
    "                                            amod_pairs.append(k.text+' '+j.text+' '+token.text)\n",
    "                                    mtch = re.search(re.escape(str1),re.escape(str2))\n",
    "                                    if mtch is not None:\n",
    "                                        amod_pairs.remove(str1)\n",
    "                        if token.pos_ is 'VERB':\n",
    "                            for j in token.lefts:\n",
    "                                if j.dep_ is 'advmod' and j.pos_ is 'ADV':\n",
    "                                    advmod_pairs.append(j.text+' '+token.text)\n",
    "                                if j.dep_ is 'neg' and j.pos_ is 'ADV':\n",
    "                                    neg_pairs.append(j.text+' '+token.text)\n",
    "                            for j in token.rights:\n",
    "                                if j.dep_ is 'advmod'and j.pos_ is 'ADV':\n",
    "                                    advmod_pairs.append(token.text+' '+j.text)\n",
    "                        if token.pos_ is 'ADJ':\n",
    "                            for j,h in zip(token.rights,token.lefts):\n",
    "                                if j.dep_ is 'xcomp' and h.dep_ is not 'neg':\n",
    "                                    for k in j.lefts:\n",
    "                                        if k.dep_ is 'aux':\n",
    "                                            xcomp_pairs.append(token.text+' '+k.text+' '+j.text)\n",
    "                                elif j.dep_ is 'xcomp' and h.dep_ is 'neg':\n",
    "                                    if k.dep_ is 'aux':\n",
    "                                            neg_pairs.append(h.text +' '+token.text+' '+k.text+' '+j.text)\n",
    "\n",
    "                else:\n",
    "                    enemlist.append(enem_list)\n",
    "                    doc = nlp(line)\n",
    "                    str1=''\n",
    "                    str2=''\n",
    "                    for token in doc:\n",
    "                        if token.pos_ is 'NOUN':\n",
    "                            for j in token.lefts:\n",
    "                                if j.dep_ == 'compound':\n",
    "                                    ecompound_pairs.append((j.text+' '+token.text,token.text))\n",
    "                                if j.dep_ is 'amod' and j.pos_ is 'ADJ': #primary condition\n",
    "                                    str1 = j.text+' '+token.text\n",
    "                                    eamod_pairs.append(j.text+' '+token.text)\n",
    "                                    for k in j.lefts:\n",
    "                                        if k.dep_ is 'advmod': #secondary condition to get adjective of adjectives\n",
    "                                            str2 = k.text+' '+j.text+' '+token.text\n",
    "                                            eamod_pairs.append(k.text+' '+j.text+' '+token.text)\n",
    "                                    mtch = re.search(re.escape(str1),re.escape(str2))\n",
    "                                    if mtch is not None:\n",
    "                                        eamod_pairs.remove(str1)\n",
    "                        if token.pos_ is 'VERB':\n",
    "                            for j in token.lefts:\n",
    "                                if j.dep_ is 'advmod' and j.pos_ is 'ADV':\n",
    "                                    eadvmod_pairs.append(j.text+' '+token.text)\n",
    "                                if j.dep_ is 'neg' and j.pos_ is 'ADV':\n",
    "                                    eneg_pairs.append(j.text+' '+token.text)\n",
    "                            for j in token.rights:\n",
    "                                if j.dep_ is 'advmod'and j.pos_ is 'ADV':\n",
    "                                    eadvmod_pairs.append(token.text+' '+j.text)\n",
    "                        if token.pos_ is 'ADJ':\n",
    "                            for j in token.rights:\n",
    "                                if j.dep_ is 'xcomp':\n",
    "                                    for k in j.lefts:\n",
    "                                        if k.dep_ is 'aux':\n",
    "                                            excomp_pairs.append(token.text+' '+k.text+' '+j.text)\n",
    "            pairs = list(set(amod_pairs+advmod_pairs+neg_pairs+xcomp_pairs))\n",
    "            print(pairs)\n",
    "            epairs = list(set(eamod_pairs+eadvmod_pairs+eneg_pairs+excomp_pairs))\n",
    "            for i in range(len(pairs)):\n",
    "                if len(compound_pairs)!=0:\n",
    "                    for comp in compound_pairs:\n",
    "                        mtch = re.search(re.escape(comp[1]),re.escape(pairs[i]))\n",
    "                        if mtch is not None:\n",
    "                            pairs[i] = pairs[i].replace(mtch.group(),comp[0])\n",
    "            for i in range(len(epairs)):\n",
    "                if len(ecompound_pairs)!=0:\n",
    "                    for comp in ecompound_pairs:\n",
    "                        mtch = re.search(re.escape(comp[1]),re.escape(epairs[i]))\n",
    "                        if mtch is not None:\n",
    "                            epairs[i] = epairs[i].replace(mtch.group(),comp[0])\n",
    "\n",
    "        aspect_terms.append(pairs)\n",
    "        comp_terms.append(compound_pairs)\n",
    "        easpect_terms.append(epairs)\n",
    "        ecomp_terms.append(ecompound_pairs)\n",
    "        enemy.append(enemlist)\n",
    "    data['compound_nouns'] = comp_terms\n",
    "    data['aspect_keywords'] = aspect_terms\n",
    "    data['competition'] = enemy\n",
    "    data['competition_comp_nouns'] = ecomp_terms\n",
    "    data['competition_aspects'] = easpect_terms\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/242 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['big bottle', 'Indian brand', 'LONG time', 'gradually improved', 'single user']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                                 | 3/242 [00:00<00:14, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n't need\", 'oily scalp', 'naturally straight hair', 'straight hair', 'use afterward', 'lathers easily']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                                | 4/242 [00:00<00:17, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['ayurvedic shampoos', 'Then call']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                | 6/242 [00:00<00:17, 13.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['many shampoos', 'Nice product', 'really works', 'then tried']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                               | 8/242 [00:00<00:17, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                             | 11/242 [00:00<00:14, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good product', 'Best deal']\n",
      "['pack properly', 'not pack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                            | 13/242 [00:00<00:14, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['always liked']\n",
      "[\"n't use\"]\n",
      "['Very good shampoo', 'dry hair', 'frizzy hair', 'good shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                           | 16/242 [00:00<00:13, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazing packaging', 'best shampoo']\n",
      "['So utilize', 'dry hair']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████                                                                           | 18/242 [00:01<00:15, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worked well', 'Really worked']\n",
      "['was all', 'not sealed', 'cost dearly', 'little things']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                          | 20/242 [00:01<00:16, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['nice shampoo', 'Very nice shampoo', 'super deal']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▋                                                                         | 23/242 [00:01<00:14, 15.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great shampoo']\n",
      "['Great product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                        | 25/242 [00:01<00:14, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Good product', 'great value']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▎                                                                       | 28/242 [00:01<00:12, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['completely setisfied', 'last years']\n",
      "['Nice foam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████                                                                       | 30/242 [00:01<00:12, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['not reduced', \"n't buy\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▋                                                                      | 32/242 [00:01<00:12, 16.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not sealed', 'sealed well']\n",
      "['really moisturizes', 'is yet', 'used once', 'Good product', 'several times', 'barely used']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▍                                                                     | 34/242 [00:02<00:15, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good product']\n",
      "['Great deal', 'Nice offer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████                                                                     | 36/242 [00:02<00:13, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                    | 38/242 [00:02<00:13, 15.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['then have', \"n't buy\", 'more hair']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▍                                                                   | 40/242 [00:02<00:12, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['many shampoos', 'single suits', 'Amazing shampoo', 'thick hairs', \"'s then\", 'rough hairs']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████                                                                   | 42/242 [00:02<00:11, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['much quantity']\n",
      "['Whole bottle', 'whole bottle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▋                                                                  | 44/242 [00:02<00:11, 16.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n't support\", \"n't need\", 'Great stuff', 'great product']\n",
      "['not decreased']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▍                                                                 | 46/242 [00:02<00:12, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Very good product', 'good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████                                                                 | 48/242 [00:03<00:11, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very good product', 'continuously using', 'good product']\n",
      "['Bad packaging']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▋                                                                | 50/242 [00:03<00:11, 16.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['several shampoos', 'reduced completely', 'real hairfall', 'other shampoos', 'anti hairfall', 'same check', 'Promising Shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▍                                                               | 52/242 [00:03<00:13, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['damaged condition']\n",
      "['Good shampoo', 'Nice product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████████████████▋                                                              | 56/242 [00:03<00:10, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very good product', 'good product']\n",
      "[]\n",
      "['great change']\n",
      "['anti variant', 'Awesome shampoo', 'very mild shampoo', 'mild shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████                                                             | 60/242 [00:03<00:09, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best shampoo', 'good fragrance']\n",
      "['So use', 'Currently using', 'dry hair']\n",
      "['few days', 'Best one', 'grt experence']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████████████████                                                            | 63/242 [00:03<00:09, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very good shampoo', 'nice packeging', 'good shampoo']\n",
      "[]\n",
      "[]\n",
      "['Good life', 'long life']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▍                                                          | 67/242 [00:03<00:08, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nice shampoo', 'great smell']\n",
      "['Nice product']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▊                                                         | 71/242 [00:03<00:07, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['really working']\n",
      "['Good quality']\n",
      "['Nice one']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▊                                                        | 74/242 [00:04<00:06, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Nice product']\n",
      "['nice shampoo']\n",
      "['nice product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████                                                       | 78/242 [00:04<00:06, 26.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n't make\", 'really like']\n",
      "['is really', 'very good shampoo', 'good shampoo']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████                                                      | 81/242 [00:04<00:06, 26.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recommend all', 'nt recommend', 'first wash']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████████                                                     | 84/242 [00:04<00:05, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['Good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▍                                                   | 88/242 [00:04<00:05, 27.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "['good price']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▊                                                  | 92/242 [00:04<00:05, 28.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Little bit', 'covered tightly']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▏                                                | 96/242 [00:04<00:05, 28.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good shampoo']\n",
      "[]\n",
      "['Never buy']\n",
      "['nice product', 'Nice product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████                                               | 100/242 [00:04<00:04, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Best performance', 'assured product', 'Best assured product']\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▍                                             | 104/242 [00:05<00:04, 29.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other shampoo']\n",
      "['Bad delivery']\n",
      "['very mild shampoo', 'silky hairs', 'good fall', 'prime packing', 'mild shampoo', 'Fantastic shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████▎                                            | 107/242 [00:05<00:05, 26.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['favorite nyle']\n",
      "['Good product', 'good product']\n",
      "[]\n",
      "['nice product', 'Very nice product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▋                                           | 111/242 [00:05<00:04, 28.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████                                          | 115/242 [00:05<00:04, 29.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very good product', 'good product']\n",
      "[]\n",
      "['reduces slightly', 'Nice consistency', 'own experience']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████                                         | 118/242 [00:05<00:04, 28.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good qulity']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████                                        | 121/242 [00:05<00:04, 26.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other items']\n",
      "['last years', 'not required', 'best shampoo', 'Always recommend', 'ever used']\n",
      "['Nice product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████▉                                       | 124/242 [00:05<00:04, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soft hairs', 'silky hairs', 'less hair']\n",
      "['Best product']\n",
      "['Average product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████▉                                      | 127/242 [00:05<00:04, 25.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['really reduced', 'seen too']\n",
      "[\"n't stop\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████▉                                     | 130/242 [00:06<00:04, 26.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best products', \"n't go\", 'literally reduced']\n",
      "[\"n't suit\", 'not recommend', 'oily scalps', 'oily scalp', 'suit all']\n",
      "['Nice shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████▉                                    | 133/242 [00:06<00:04, 24.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nice product']\n",
      "[]\n",
      "['Bad product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▉                                   | 136/242 [00:06<00:04, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Average product']\n",
      "['n’t meet', 'last purchase']\n",
      "['awesome product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████▉                                  | 139/242 [00:06<00:03, 26.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['good quality', 'excellent service', 'Excellent product']\n",
      "['good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████▉                                 | 142/242 [00:06<00:03, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural product']\n",
      "['Awesome product', 'unbelievably low price', 'low price']\n",
      "['Good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████▉                                | 145/242 [00:06<00:03, 26.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Good product']\n",
      "['good price']\n",
      "['defective lid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▎                              | 149/242 [00:06<00:03, 26.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['frizzy hair', \"'s really\", 'mild shampoo']\n",
      "['good result', 'Very nice shampoo', 'best shampoo', 'nice shampoo', 'first use']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████▌                             | 153/242 [00:06<00:03, 28.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['much seems']\n",
      "['Nice shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████▌                            | 156/242 [00:07<00:03, 26.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['Nice shampoo']\n",
      "['regular use', 'definitely go', 'go again']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████▉                           | 160/242 [00:07<00:03, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['buy again', 'competitive price']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████▉                          | 163/242 [00:07<00:03, 25.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"n't help\"]\n",
      "['great deal']\n",
      "['best deal']\n",
      "['Exact product', 'is afterwards', 'Good work']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▏                        | 167/242 [00:07<00:02, 26.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['ever tried']\n",
      "['Good shampoo']\n",
      "['Never Recommend']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████▌                       | 171/242 [00:07<00:02, 27.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice shampoo', 'nice smell']\n",
      "['Good one']\n",
      "['Good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████▌                      | 174/242 [00:07<00:02, 26.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['smooth texture', 'free shampoo', 'first time', 'other hair', 'Good product', 'purchase well']\n",
      "['Good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▌                     | 177/242 [00:07<00:02, 24.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good product']\n",
      "['Nice product']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████▊                    | 181/242 [00:08<00:02, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good product']\n",
      "[]\n",
      "['Anti shampoo']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████▏                  | 185/242 [00:08<00:02, 28.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Good product']\n",
      "['costly shampoos']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▍                 | 189/242 [00:08<00:01, 29.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good delivery']\n",
      "['GOOD PRODUCT']\n",
      "['herbal shampoo', 'Very nice shampoo', 'nice shampoo', 'Affordable shampoo', 'low price']\n",
      "['wash only', 'dry hair', 'Made again', 'ever seen', 'rough hair', 'probably used', 'second thing', 'feel again', 'real shine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▊                | 193/242 [00:08<00:01, 28.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████████▊               | 196/242 [00:08<00:01, 27.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agood brand', 'purchase again']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▊              | 199/242 [00:08<00:01, 27.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Not expected']\n",
      "['Nice product']\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████             | 203/242 [00:08<00:01, 28.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Nice product']\n",
      "['Good shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████            | 206/242 [00:08<00:01, 28.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good quality']\n",
      "['good product']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████████▍          | 210/242 [00:09<00:01, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['very less price', 'Nice product', 'less price']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▋         | 214/242 [00:09<00:00, 29.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great shampoo', 'buy again']\n",
      "['NICE PRODUCT', 'REDUCE ALSO']\n",
      "['almost gone']\n",
      "[\"n't use\", \"n't work\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████        | 218/242 [00:09<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['nt buy', 'good hair']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████       | 221/242 [00:09<00:00, 28.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good quality']\n",
      "['Best shampoo']\n",
      "['frizzy hair', 'n frizzy hair']\n",
      "['Excellent product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 225/242 [00:09<00:00, 29.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good bargain']\n",
      "[]\n",
      "[]\n",
      "['Best shampoo', 'anti hair', 'ever used', 'best shampoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████▋    | 229/242 [00:09<00:00, 29.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good product']\n",
      "['tightly fix', 'small suggestion']\n",
      "[]\n",
      "['wash gently']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████   | 233/242 [00:09<00:00, 30.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hopefully going', 'important part', 'most important part', 'free shampoo', 'many stands', 'continue forever', 'used before', 'is absolutely', 'best shampoo', 'fantastic shampoo', 'stopped completely', 'ever used', 'Honestly use', 'not stopping']\n",
      "[]\n",
      "['certainly recommend', 'Amazing Product']\n",
      "['Good product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████▎ | 237/242 [00:09<00:00, 25.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['last long', 'mild scent', 'Great buy']\n",
      "[]\n",
      "['very nice Product', 'nice product', 'nice Product']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▎| 240/242 [00:10<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 242/242 [00:10<00:00, 23.76it/s]\n"
     ]
    }
   ],
   "source": [
    "data1 = get_aspect_adj(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>neutral_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_index, aspect_adj_string, pos_score, neg_score, compound_score, neutral_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame(columns = ['row_index','aspect_adj_string','pos_score','neg_score','compound_score','neutral_score'])\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "my_df = pd.DataFrame(columns = ['row_index','aspect_adj_string','pos_score','neg_score','compound_score','neutral_score'])\n",
    "global_sentiment = {}\n",
    "for aspect_adj_tuple in data1.aspect_keywords.iteritems():\n",
    "    row_sentiment = {}\n",
    "    for text in aspect_adj_tuple[1]:\n",
    "        sentiment_array = []\n",
    "        polarity = analyser.polarity_scores(text)\n",
    "#         print(polarity)\n",
    "#         sentiment_array.append(polarity['pos'])\n",
    "#         sentiment_array.append(polarity['neg'])\n",
    "#         row_sentiment[text] = sentiment_array\n",
    "        my_df = my_df.append({'row_index':aspect_adj_tuple[0],'aspect_adj_string':text,'pos_score':polarity['pos'],'neg_score':polarity['neg'],'compound_score':polarity['compound'],'neutral_score':polarity['neu']},ignore_index=True)\n",
    "#     global_sentiment[aspect_adj_tuple[0]] = row_sentiment\n",
    "    \n",
    "# print(global_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the data to remove the non-sentimental/garbage/gray sentiments from entire dataframe\n",
    "final_df = my_df[((my_df['compound_score']>0.1) | (my_df['compound_score']< -0.1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>neutral_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_index, aspect_adj_string, pos_score, neg_score, compound_score, neutral_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificaction on filtered data\n",
    "final_df[(final_df['compound_score']<0) & (final_df['pos_score']> final_df['neg_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df['final_sentiment'] = ['pos' if i>0 else 'neg' for i in final_df['compound_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for row_txt in final_df.aspect_adj_string.iteritems():\n",
    "    doc = nlp(row_txt[1])\n",
    "    adj = []\n",
    "    aspect = []\n",
    "    for token in doc:\n",
    "\n",
    "        if (token.tag_ == 'ADV') or (token.tag_ == 'ADJ') or (token.tag_ == 'UH') or (token.tag_ == 'JJS') or (token.tag_ == 'RB') or (token.tag_ == 'JJ') :\n",
    "            adj.append(token.text)\n",
    "            \n",
    "        elif (token.tag_ == 'NN') or (token.tag_ == 'NNP') or (token.tag_ == 'VBG') or (token.tag_ == 'VB')  or (token.tag_ == 'VBN') or (token.tag_ == 'NNS'):\n",
    "            aspect.append(token.text)\n",
    "\n",
    "    if (len(adj) == len(aspect)) & (len(adj)>0):\n",
    "        final_df.at[row_txt[0],'adj']= adj\n",
    "        final_df.at[row_txt[0],'aspect']= aspect\n",
    "    elif len(adj) > len(aspect):\n",
    "        final_df.at[row_txt[0],'adj']= adj[:len(aspect)]\n",
    "        final_df.at[row_txt[0],'aspect']= aspect\n",
    "    elif  len(adj) < len(aspect):\n",
    "        final_df.at[row_txt[0],'adj']= adj\n",
    "        final_df.at[row_txt[0],'aspect']= aspect[:len(adj)]\n",
    "    else:\n",
    "        final_df.at[row_txt[0],'adj']= adj\n",
    "        final_df.at[row_txt[0],'aspect']= aspect\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"C:/Users/Dell/Pictures/senti/afteraspect.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>compound_score</th>\n",
       "      <th>neutral_score</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>adj</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gradually improved</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.244</td>\n",
       "      <td>pos</td>\n",
       "      <td>gradually</td>\n",
       "      <td>improved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>naturally straight hair</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.513</td>\n",
       "      <td>pos</td>\n",
       "      <td>[naturally]</td>\n",
       "      <td>[hair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>straight hair</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.345</td>\n",
       "      <td>pos</td>\n",
       "      <td>[straight]</td>\n",
       "      <td>[hair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>lathers easily</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.294</td>\n",
       "      <td>pos</td>\n",
       "      <td>[easily]</td>\n",
       "      <td>[lathers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.263</td>\n",
       "      <td>pos</td>\n",
       "      <td>[Nice]</td>\n",
       "      <td>[product]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index        aspect_adj_string  pos_score  neg_score  compound_score  \\\n",
       "3          2       gradually improved      0.756        0.0          0.4767   \n",
       "7          3  naturally straight hair      0.487        0.0          0.2263   \n",
       "8          3            straight hair      0.655        0.0          0.2263   \n",
       "10         3           lathers easily      0.706        0.0          0.3400   \n",
       "14         7             Nice product      0.737        0.0          0.4215   \n",
       "\n",
       "    neutral_score final_sentiment          adj     aspect  \n",
       "3           0.244             pos    gradually   improved  \n",
       "7           0.513             pos  [naturally]     [hair]  \n",
       "8           0.345             pos   [straight]     [hair]  \n",
       "10          0.294             pos     [easily]  [lathers]  \n",
       "14          0.263             pos       [Nice]  [product]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdreg=final_df[['row_index','aspect_adj_string','final_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gradually improved</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>naturally straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>lathers easily</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index        aspect_adj_string final_sentiment\n",
       "3          2       gradually improved             pos\n",
       "7          3  naturally straight hair             pos\n",
       "8          3            straight hair             pos\n",
       "10         3           lathers easily             pos\n",
       "14         7             Nice product             pos"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirdreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata_check    = pd.merge(data,thirdreg[\"row_index\"],on = \"row_index\",how = \"left\",indicator = True)\n",
    "geonew_check     = geodata_check[geodata_check[\"_merge\"] != 'both']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglected=geonew_check [['row_index','Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neglected['Review']= neglected['Review'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "neglected['Review']=neglected['Review'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8682: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#nltk vader lexicon \n",
    "final_sentiment=[]\n",
    "for i in neglected['Review'].values:\n",
    "    try:\n",
    "        senti=SentimentIntensityAnalyzer()\n",
    "        analysis=senti.polarity_scores(i)\n",
    "        final_sentiment.append(analysis['compound'])\n",
    "    except:\n",
    "        final_sentiment.append(0)\n",
    "neglected['final_sentiment']=final_sentiment\n",
    "\n",
    "pos=neglected[['row_index','Review','final_sentiment']][neglected.final_sentiment>0]\n",
    "neg=neglected[['row_index','Review','final_sentiment']][neglected.final_sentiment<0]\n",
    "hpos=neglected[['row_index','Review','final_sentiment']][neglected.final_sentiment>0.75]\n",
    "hneg=neglected[['row_index','Review','final_sentiment']][neglected.final_sentiment<-0.25]\n",
    "\n",
    "#Converting the polarity values from continuous to categorical\n",
    "neglected['final_sentiment'][neglected.final_sentiment==0]= 0\n",
    "neglected['final_sentiment'][neglected.final_sentiment > 0]= 1\n",
    "neglected['final_sentiment'][neglected.final_sentiment< 0]= -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>noting special  ok product</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>review  good</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>damaged  unexpectedlly    one bottle is damaged</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>not entirely ayurvedic though       all these ...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>good for hair loss    it s good for hair loss</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_index                                             Review  \\\n",
       "0         0                        noting special  ok product    \n",
       "1         1                                       review  good   \n",
       "6         4    damaged  unexpectedlly    one bottle is damaged   \n",
       "7         5  not entirely ayurvedic though       all these ...   \n",
       "8         6     good for hair loss    it s good for hair loss    \n",
       "\n",
       "   final_sentiment  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "6             -1.0  \n",
       "7             -1.0  \n",
       "8              1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value = {1.0:'pos',-1.0:'neg',0.0:'neu'} \n",
    "neglected.final_sentiment = [value[item] for item in neglected.final_sentiment]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>noting special  ok product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>review  good</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>damaged  unexpectedlly    one bottle is damaged</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>not entirely ayurvedic though       all these ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>good for hair loss    it s good for hair loss</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_index                                             Review final_sentiment\n",
       "0         0                        noting special  ok product              pos\n",
       "1         1                                       review  good             pos\n",
       "6         4    damaged  unexpectedlly    one bottle is damaged             neg\n",
       "7         5  not entirely ayurvedic though       all these ...             neg\n",
       "8         6     good for hair loss    it s good for hair loss              pos"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake_nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rake_nltk) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk->rake_nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk->rake_nltk) (3.4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import RAKE\n",
    "!pip install rake_nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords \n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aspect_adj_string =[]\n",
    "for i in neglected['Review'].values:\n",
    "    try:\n",
    "        r= Rake()\n",
    "        r = Rake(min_length=1, max_length=3)\n",
    "        a=r.extract_keywords_from_text(i)\n",
    "        b=r.get_ranked_phrases()[:3]\n",
    "        aspect_adj_string.append(b)\n",
    "    except:\n",
    "        aspect_adj_string.append(0)\n",
    "neglected['aspect_adj_string']=aspect_adj_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25</td>\n",
       "      <td>nice  nice</td>\n",
       "      <td>pos</td>\n",
       "      <td>[nice nice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>188</td>\n",
       "      <td>good  good</td>\n",
       "      <td>pos</td>\n",
       "      <td>[good good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>82</td>\n",
       "      <td>love this product  i use this product form fou...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[use, product, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>223</td>\n",
       "      <td>too good  awesome for dry n frizzy hair</td>\n",
       "      <td>pos</td>\n",
       "      <td>[good awesome]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>216</td>\n",
       "      <td>worth of money  gd product my hairfall almost ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[money gd product, hairfall almost gone, worth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>218</td>\n",
       "      <td>shampoo bottle leaked inside the package    sh...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[package]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>36</td>\n",
       "      <td>doesnot suit me  my hair fall started even more</td>\n",
       "      <td>neu</td>\n",
       "      <td>[doesnot suit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>45</td>\n",
       "      <td>keeps hair soft  keeps hair soft but yes hair ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[yes hair fall, decreased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>90</td>\n",
       "      <td>good  good</td>\n",
       "      <td>pos</td>\n",
       "      <td>[good good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_index                                             Review  \\\n",
       "32         25                                         nice  nice   \n",
       "230       188                                         good  good   \n",
       "104        82  love this product  i use this product form fou...   \n",
       "267       223           too good  awesome for dry n frizzy hair    \n",
       "260       216  worth of money  gd product my hairfall almost ...   \n",
       "262       218  shampoo bottle leaked inside the package    sh...   \n",
       "45         36   doesnot suit me  my hair fall started even more    \n",
       "56         45  keeps hair soft  keeps hair soft but yes hair ...   \n",
       "112        90                                         good  good   \n",
       "25         20                                                NaN   \n",
       "\n",
       "    final_sentiment                                aspect_adj_string  \n",
       "32              pos                                      [nice nice]  \n",
       "230             pos                                      [good good]  \n",
       "104             pos                             [use, product, love]  \n",
       "267             pos                                   [good awesome]  \n",
       "260             pos  [money gd product, hairfall almost gone, worth]  \n",
       "262             neg                                        [package]  \n",
       "45              neu                                   [doesnot suit]  \n",
       "56              pos                       [yes hair fall, decreased]  \n",
       "112             pos                                      [good good]  \n",
       "25              neu                                                0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglected.sample(10)\n",
    "#neglected=[['row_index','final_sentiment','aspect_adj_string','Review']]\n",
    "#thirdreg=[['row_index','Review','final_sentiment','aspect_adj_string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>171</td>\n",
       "      <td>nice shampoo</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>151</td>\n",
       "      <td>best shampoo</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>186</td>\n",
       "      <td>Good product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>26</td>\n",
       "      <td>Good product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>130</td>\n",
       "      <td>best products</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>233</td>\n",
       "      <td>stopped completely</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>144</td>\n",
       "      <td>Good product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>201</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>66</td>\n",
       "      <td>Good life</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>177</td>\n",
       "      <td>Good product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_index   aspect_adj_string final_sentiment\n",
       "228       171        nice shampoo             pos\n",
       "208       151        best shampoo             pos\n",
       "243       186        Good product             pos\n",
       "43         26        Good product             pos\n",
       "176       130       best products             pos\n",
       "306       233  stopped completely             neg\n",
       "199       144        Good product             pos\n",
       "265       201        Nice product             pos\n",
       "112        66           Good life             pos\n",
       "239       177        Good product             pos"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirdreg.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Noting Special. Ok Product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Review. Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Indian brand keeping to its name, best for me!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Satisfied. Bought it for INR 152 during the Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Damaged. Unexpectedlly... One bottle is damaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                             Review\n",
       "0          0                        Noting Special. Ok Product.\n",
       "1          1                                       Review. Good\n",
       "2          2  Indian brand keeping to its name, best for me!...\n",
       "3          3  Satisfied. Bought it for INR 152 during the Am...\n",
       "4          4    Damaged. Unexpectedlly... One bottle is damaged"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geodata_check    = pd.merge(thirdreg,data[\"Review\"],on = \"row_index\",how = \"left\",indicator = True)\n",
    "#geonew_check     = geodata_check[geodata_check[\"_merge\"] != 'both']\n",
    "initial.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>noting special  ok product</td>\n",
       "      <td>pos</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>review  good</td>\n",
       "      <td>pos</td>\n",
       "      <td>[review good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>damaged  unexpectedlly    one bottle is damaged</td>\n",
       "      <td>neg</td>\n",
       "      <td>[damaged]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>not entirely ayurvedic though       all these ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[entirely ayurvedic though, called ayurvedic s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>good for hair loss    it s good for hair loss</td>\n",
       "      <td>pos</td>\n",
       "      <td>[hair loss, good]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_index                                             Review  \\\n",
       "0         0                        noting special  ok product    \n",
       "1         1                                       review  good   \n",
       "6         4    damaged  unexpectedlly    one bottle is damaged   \n",
       "7         5  not entirely ayurvedic though       all these ...   \n",
       "8         6     good for hair loss    it s good for hair loss    \n",
       "\n",
       "  final_sentiment                                  aspect_adj_string  \n",
       "0             pos                                                 []  \n",
       "1             pos                                      [review good]  \n",
       "6             neg                                          [damaged]  \n",
       "7             neg  [entirely ayurvedic though, called ayurvedic s...  \n",
       "8             pos                                  [hair loss, good]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neglected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "neglected.to_csv(\"C:/Users/Dell/Pictures/senti/neglectedfinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdreg.to_csv(\"C:/Users/Dell/Pictures/senti/thirdregfinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Noting Special. Ok Product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Review. Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Indian brand keeping to its name, best for me!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Satisfied. Bought it for INR 152 during the Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Damaged. Unexpectedlly... One bottle is damaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                             Review\n",
       "0          0                        Noting Special. Ok Product.\n",
       "1          1                                       Review. Good\n",
       "2          2  Indian brand keeping to its name, best for me!...\n",
       "3          3  Satisfied. Bought it for INR 152 during the Am...\n",
       "4          4    Damaged. Unexpectedlly... One bottle is damaged"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gradually improved</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>naturally straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>lathers easily</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index        aspect_adj_string final_sentiment\n",
       "3          2       gradually improved             pos\n",
       "7          3  naturally straight hair             pos\n",
       "8          3            straight hair             pos\n",
       "10         3           lathers easily             pos\n",
       "14         7             Nice product             pos"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirdreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_index', 'Review', 'final_sentiment', 'aspect_adj_string'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#geodata_check    = pd.merge(thirdreg,data[\"Review\"],on = \"row_index\",how = \"left\",indicator = True)\n",
    "#geonew_check     = geodata_check[geodata_check[\"_merge\"] != 'both']\n",
    "neglected.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[review good]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[damaged]</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>[entirely ayurvedic though, called ayurvedic s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>[hair loss, good]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_index                                  aspect_adj_string final_sentiment\n",
       "0         0                                                 []             pos\n",
       "1         1                                      [review good]             pos\n",
       "6         4                                          [damaged]             neg\n",
       "7         5  [entirely ayurvedic though, called ayurvedic s...             neg\n",
       "8         6                                  [hair loss, good]             pos"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customized=neglected[['row_index','aspect_adj_string','final_sentiment']]\n",
    "customized.head()\n",
    "#customized.to_csv(\"C:/Users/Dell/Pictures/senti/customizedfinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>aspect_adj_string</th>\n",
       "      <th>final_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>gradually improved</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>naturally straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>straight hair</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>lathers easily</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index        aspect_adj_string final_sentiment\n",
       "3          2       gradually improved             pos\n",
       "7          3  naturally straight hair             pos\n",
       "8          3            straight hair             pos\n",
       "10         3           lathers easily             pos\n",
       "14         7             Nice product             pos"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thirdreg.head()\n",
    "#thirdreg.to_csv(\"C:/Users/Dell/Pictures/senti/thirdreg.csv\")\n",
    "thirdreg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [customized,thirdreg]\n",
    "customizedalgorithm = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "customized.to_csv(\"C:/Users/Dell/Pictures/senti/customized rule based algorithm final op.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([customized,thirdreg], axis=1, sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
