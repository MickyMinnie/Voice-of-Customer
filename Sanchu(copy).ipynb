{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(r\"C:/Users/Dell/Pictures/ccc.xlsx\")\n",
    "#removing all punctuations\n",
    "data['content'] = data['content'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment part\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "#nltk vader lexicon \n",
    "final_sentimentt=[]\n",
    "for i in data['content'].values:\n",
    "    try:\n",
    "        senti=SentimentIntensityAnalyzer()\n",
    "        analysis=senti.polarity_scores(i)\n",
    "        final_sentimentt.append(analysis['compound'])\n",
    "    except:\n",
    "        final_sentimentt.append(0)\n",
    "data['final_sentimentt']=final_sentimentt\n",
    "\n",
    "pos=data[['row_index','content','final_sentimentt','rating']][data.final_sentimentt>0]\n",
    "neg=data[['row_index','content','final_sentimentt','rating']][data.final_sentimentt<0]\n",
    "hpos=data[['row_index','content','final_sentimentt','rating']][data.final_sentimentt>0.75]\n",
    "hneg=data[['row_index','content','final_sentimentt','rating']][data.final_sentimentt<-0.25]\n",
    "\n",
    "#Converting the polarity values from continuous to categorical\n",
    "data['final_sentimentt'][data.final_sentimentt==0]= 0\n",
    "data['final_sentimentt'][data.final_sentimentt > 0]= 1\n",
    "data['final_sentimentt'][data.final_sentimentt< 0]= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to needed format(senti)\n",
    "value = {1.0:'pos',-1.0:'neg',0.0:'neu'} \n",
    "data.final_sentimentt = [value[item] for item in data.final_sentimentt]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('C:/Users/Dell/Pictures/ckcheck.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to needed format(for last check verification to get exact results(for avoiding type1 error))\n",
    "value = {1:'1.0 out of 5 stars',2:'2.0 out of 5 stars',3:'3.0 out of 5 stars',4:'4.0 out of 5 stars',5:'5.0 out of 5 stars'} \n",
    "data.rating = [value[item] for item in data.rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last check\n",
    "places=['1.0 out of 5 stars','2.0 out of 5 stars']\n",
    "#xtracting loc and location \n",
    "pattern='|'.join(places)\n",
    "x=data['rating'].str.contains(pattern)\n",
    "data['final_sentimentt']=x.replace((True,False),('neg',data['final_sentimentt']))\n",
    "data= data[pd.notnull(data['content'])] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake_nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rake_nltk) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk->rake_nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk->rake_nltk) (3.4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Aspect extraction part\n",
    "!pip install rake_nltk\n",
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords \n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting aspect with higher ranking phrases (top5 min)\n",
    "aspect_adj_string =[]\n",
    "for i in data['content'].values:\n",
    "    try:\n",
    "        r= Rake()\n",
    "        r = Rake(min_length=1, max_length=2)\n",
    "        a=r.extract_keywords_from_text(i)\n",
    "        b=r.get_ranked_phrases()[:5]\n",
    "        aspect_adj_string.append(b)\n",
    "    except:\n",
    "        aspect_adj_string.append(0)\n",
    "data['aspect_adj_string']=aspect_adj_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"C:/Users/Dell/Downloads/ccc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sample aspects\n",
    "[x for x in data.aspect_adj_string.sample(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 5.789640426635742 secs.\n"
     ]
    }
   ],
   "source": [
    "#Topic modelling\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords  \n",
    "import nltk\n",
    "import re\n",
    "from pywsd.utils import lemmatize_sentence\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"C:/Users/Dell/Pictures/sanchuop.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>row_index</th>\n",
       "      <th>Name</th>\n",
       "      <th>content</th>\n",
       "      <th>Class</th>\n",
       "      <th>rating</th>\n",
       "      <th>final_sentiment</th>\n",
       "      <th>aspect</th>\n",
       "      <th>date</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Jasmine Jebarani</td>\n",
       "      <td>My cat s name is Hary  She had to undergo hyst...</td>\n",
       "      <td>Quality of treatment</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>['undergo hysterectomy', 'successful doctors',...</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sanchu Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SJC</td>\n",
       "      <td>Sanchu animal hospital is a high quality hospi...</td>\n",
       "      <td>Quality of treatment</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>['qualified team', 'papillion dog', 'good envi...</td>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sanchu Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Krishnakumar M</td>\n",
       "      <td>Very well trained doctors  Nice professional a...</td>\n",
       "      <td>Quality of treatment</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>['visit', 'pets', 'friends']</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sanchu Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>reshika mba</td>\n",
       "      <td>The Best hospital  There are only very few avi...</td>\n",
       "      <td>Quality of treatment</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>['well thanks', 'mr annamalai', 'dr karunakara...</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sanchu Hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Manu Brahma</td>\n",
       "      <td>This is the best Animal hospital in city  I vi...</td>\n",
       "      <td>Care</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>['visited times', 'pets like', 'vaccination', ...</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sanchu Hospital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  row_index              Name  \\\n",
       "0           0          1  Jasmine Jebarani   \n",
       "1           1          2               SJC   \n",
       "2           2          3    Krishnakumar M   \n",
       "3           3          4       reshika mba   \n",
       "4           4          5       Manu Brahma   \n",
       "\n",
       "                                             content                 Class  \\\n",
       "0  My cat s name is Hary  She had to undergo hyst...  Quality of treatment   \n",
       "1  Sanchu animal hospital is a high quality hospi...  Quality of treatment   \n",
       "2  Very well trained doctors  Nice professional a...  Quality of treatment   \n",
       "3  The Best hospital  There are only very few avi...  Quality of treatment   \n",
       "4  This is the best Animal hospital in city  I vi...                  Care   \n",
       "\n",
       "   rating final_sentiment                                             aspect  \\\n",
       "0       5        positive  ['undergo hysterectomy', 'successful doctors',...   \n",
       "1       4        positive  ['qualified team', 'papillion dog', 'good envi...   \n",
       "2       5        positive                       ['visit', 'pets', 'friends']   \n",
       "3       5        positive  ['well thanks', 'mr annamalai', 'dr karunakara...   \n",
       "4       5        positive  ['visited times', 'pets like', 'vaccination', ...   \n",
       "\n",
       "        date Channel             Type  \n",
       "0 2020-03-15  Google  Sanchu Hospital  \n",
       "1 2020-04-14  Google  Sanchu Hospital  \n",
       "2 2020-03-15  Google  Sanchu Hospital  \n",
       "3 2020-03-15  Google  Sanchu Hospital  \n",
       "4 2020-02-14  Google  Sanchu Hospital  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text']=data['content']\n",
    "#replacing the punctuations\n",
    "data['text'] = data['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "#position to lowercase\n",
    "data['text']=data['text'].str.lower()\n",
    "#taking out nan\n",
    "data = data[pd.notnull(data['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['text'] = data['text'].apply(lemmatize_sentence)\n",
    "#removing stopwords \n",
    "stop= set(stopwords.words('english')) \n",
    "data['text']=data['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "#converting review column list to str\n",
    "#ind['review']=ind['review'].apply(lambda x: ' '.join(map(str,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in data.text.sample(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic modelling\n",
    "#rule based topic modelling\n",
    "#take out the all possible keywords coming under each class\n",
    "#given those keywords into each list\n",
    "#create class according to the data\n",
    "Qualityoftreatment=['surgery','successfull','doctor','employee','treatment','quality','critical','condition','trained','professional',\n",
    "                   'recommend','hospital','medical','equipment','treat','suffer','problem','animal','killer','effect','clinic','effective',\n",
    "                    'examine','pain','injection','technically','experience','function','diagnose','medicine','pet','dog','injured','bleed',\n",
    "                   'carelessness','collapse','high','dosage','well','maintain','locate','operation','operate','team','service',\n",
    "                   'multispeciality','inject','treat','reaction','allergic','advice','emergency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hygiene=['facility','clean','environment','place','taxi','park','board','atmosphere','accommodative','maintenance']\n",
    "Charges=['discount','charge','price','fees']\n",
    "Care=['care','staff','kindness','help']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "6\n",
      "4\n",
      "18\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "7\n",
      "4\n",
      "16\n",
      "4\n",
      "5\n",
      "58\n",
      "7\n",
      "7\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def matcher(query):\n",
    "    s=0\n",
    "    it=0\n",
    "    wl=0\n",
    "    c=0\n",
    "         \n",
    "\n",
    "    for x in query: \n",
    "        if x in Qualityoftreatment:        \n",
    "            s +=1                    \n",
    "        if x in Hygiene:\n",
    "            it +=1                \n",
    "        if x in Charges:\n",
    "            wl +=1\n",
    "        if x in Care:\n",
    "            c +=1\n",
    "        \n",
    "    max_count=max(s,it,wl,c)\n",
    "    print(max_count)\n",
    "    if max_count==s:\n",
    "        return 'Qualityoftreatment'\n",
    "    elif max_count==it:\n",
    "        return 'Hygiene'\n",
    "    elif max_count==wl:\n",
    "        return 'Charges'\n",
    "    elif max_count==c:\n",
    "        return 'Care'\n",
    "data['class1']=data['text'].apply(matcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher(query):\n",
    "    s=0\n",
    "    it=0\n",
    "    wl=0\n",
    "    c=0\n",
    "         \n",
    "\n",
    "    for x in query: \n",
    "        if x in Qualityoftreatment:        \n",
    "            s +=1                    \n",
    "        if x in Hygiene:\n",
    "            it +=1                \n",
    "        if x in Charges:\n",
    "            wl +=1\n",
    "        if x in Care:\n",
    "            c +=1\n",
    "        \n",
    "    max_count=max(s,it,wl,c)\n",
    "    max_count1=max_count-1\n",
    "    if max_count1==s:\n",
    "        return 'Qualityoftreatment'\n",
    "    elif max_count1==it:\n",
    "        return 'Hygiene'\n",
    "    elif max_count1==wl:\n",
    "        return 'Charges'\n",
    "    elif max_count1==c:\n",
    "        return 'Care'\n",
    "data['class2']=data['text'].apply(matcher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'row_index', 'Name', 'content', 'Class', 'rating',\n",
       "       'final_sentiment', 'aspect', 'date', 'Channel', 'Type', 'text',\n",
       "       'class1', 'class2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.melt(id_vars =['Unnamed: 0', 'row_index', 'Name','content','Class','rating','date','final_sentiment','aspect',\n",
    "            'text','Type','Channel'], value_vars =['class1','class2'],  \n",
    "        var_name ='Variable_column', value_name ='classes') \n",
    "       \n",
    "data = data[pd.notnull(data['classes'])]\n",
    "\n",
    "data=data.drop(['Variable_column'],axis=1)\n",
    "\n",
    "data.to_excel('C:/Users/Dell/Downloads/sanchuop.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "one_year_review=pd.read_excel(\"C:/Users/Dell/Pictures/sanchuclassstr.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review['date']=one_year_review['date'].str.replace(\"months ago\",\" \").str.replace(\"month ago\",\" \") \n",
    "\n",
    "one_year_review['month'] = one_year_review['date'].str.strip() \n",
    "\n",
    "one_year_review['curr_date'] = pd.Timestamp('2020-05-14') \n",
    "\n",
    "one_year_review['curr_date'].dtype \n",
    "\n",
    "one_year_review['month_days'] = one_year_review['month'].astype(int)*30 \n",
    "\n",
    "one_year_review['review_date'] = one_year_review['curr_date'] - pd.to_timedelta(one_year_review['month_days'],unit='D') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review=one_year_review[['row_index','Name','content','Class','rating','final_sentiment','aspect_adj_string','text','review_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_review.to_excel(\"C:/Users/Dell/Pictures/sanchuop.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
